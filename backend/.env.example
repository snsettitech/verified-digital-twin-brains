
# Backend Environment Variables
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_anon_key
SUPABASE_SERVICE_KEY=your_supabase_service_role_key
JWT_SECRET=your_supabase_jwt_secret
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=your_pinecone_index_name
COHERE_API_KEY=your_cohere_api_key
ALLOWED_ORIGINS=http://localhost:3000,https://your-frontend.vercel.app
DEV_MODE=false
PORT=8000

# Stable features are enabled by default.
# Set to "false" only for emergency rollback.
ENABLE_REALTIME_INGESTION=true
ENABLE_DELPHI_RETRIEVAL=true

# Optional feature flags (opt-in)
ENABLE_ENHANCED_INGESTION=false
ENABLE_VC_ROUTES=false
ENABLE_FLASHRANK=false
ENABLE_COHERE_RERANK=true
COHERE_RERANK_MODEL=rerank-v3.5

# Embedding provider:
# - openai (default, production-safe footprint)
# - huggingface (production-safe with HF API + requirements-ml.txt)
EMBEDDING_PROVIDER=openai
HF_API_TOKEN=your_hf_api_token
HF_EMBEDDING_BACKEND=inference_api
HF_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
HF_EMBEDDING_DIMENSION=384
# Optional custom endpoint:
# HF_EMBEDDING_API_URL=https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2

# Optional: Google Gemini for free YouTube transcription
# Get from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key

# Zep/Graphiti Memory Layer (Neo4j)
# Required for Interview Mode memory persistence
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password
