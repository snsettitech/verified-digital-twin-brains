
# Backend Environment Variables
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_anon_key
SUPABASE_SERVICE_KEY=your_supabase_service_role_key
JWT_SECRET=your_supabase_jwt_secret
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=your_pinecone_index_name
COHERE_API_KEY=your_cohere_api_key
ALLOWED_ORIGINS=http://localhost:3000,https://your-frontend.vercel.app
DEV_MODE=false
PORT=8000

# Stable features are enabled by default.
# Set to "false" only for emergency rollback.
ENABLE_REALTIME_INGESTION=true
ENABLE_DELPHI_RETRIEVAL=true

# Optional feature flags (opt-in)
ENABLE_ENHANCED_INGESTION=false
ENABLE_VC_ROUTES=false
ENABLE_FLASHRANK=false
ENABLE_COHERE_RERANK=true
COHERE_RERANK_MODEL=rerank-v3.5
RETRIEVAL_MAX_SEARCH_QUERIES=4
RETRIEVAL_QUERY_EXPANSION_ENABLED=true
RETRIEVAL_HYDE_ENABLED=true
RETRIEVAL_HYDE_MIN_ANCHORS=3

# Embedding provider:
# - openai (default, production-safe footprint)
# - huggingface (production-safe with HF API + requirements-ml.txt)
EMBEDDING_PROVIDER=openai
HF_API_TOKEN=your_hf_api_token
HF_EMBEDDING_BACKEND=inference_api
HF_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
HF_EMBEDDING_DIMENSION=384
# Optional custom endpoint:
# HF_EMBEDDING_API_URL=https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2

# Optional: Google Gemini for free YouTube transcription
# Get from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key

# Langfuse tracing (required to enable production tracing)
LANGFUSE_PUBLIC_KEY=pk-lf-xxxxxxxxxxxxxxxx
LANGFUSE_SECRET_KEY=sk-lf-xxxxxxxxxxxxxxxx
# Use self-host URL if applicable (defaults to cloud.langfuse.com)
LANGFUSE_HOST=https://cloud.langfuse.com
# Optional, 0.0-1.0 sampling ratio (1.0 = trace all requests)
LANGFUSE_SAMPLING_RATE=1.0
# Optional prompt fetch from Langfuse prompt registry
LANGFUSE_PROMPT_FETCH_ENABLED=false

# Owner memory approval mode:
# true  -> interview/owner-memory writes are auto-approved (verified) by default
# false -> writes can stay in proposed state until manually approved
AUTO_APPROVE_OWNER_MEMORY=true

# Zep/Graphiti Memory Layer (Neo4j)
# Required for Interview Mode memory persistence
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# Render deployment (worker identity)
RENDER_INSTANCE_ID=

# ElevenLabs Voice
ELEVENLABS_API_KEY=your_elevenlabs_api_key
